---
title: "Predict carbon from hyperspectral data."
date: "`r Sys.Date ()`"
output: pdf_document
---

```{r, setup, include=FALSE, cache = F}
knitr::opts_chunk$set(echo = T)
knitr::opts_knit$set(root.dir = '/Users/ting15/Dropbox/Ting_Wang/rice_imaging_ms')
#knitr::opts_knit$set(root.dir = 'C:/Users/rebec/Dropbox/Ting_Wang/rice_imaging_ms')
```

```{r, echo = F, include=FALSE}
rm(list = ls())
## Load package 
list.of.packages <- c("dplyr", "reshape2", "ggplot2", "pls", "scales", "kableExtra", "ggpubr", "gridExtra", "CORElearn", "spectratrait")
invisible(lapply(list.of.packages, library, character.only = TRUE))
```
# Methods  

1. Used RReliefFexpRank algorithm to select wavelengths which had the top 300 attributes values for PLSR modeling. These wavelengths were referred to as $W_{PLSR}$.    
2. Built a PLSR model with $W_{PLSR}$ as input and carbon (C, *n*=88) as output. Methods were adapted from Burnett et al. (2021).  

```{r, include=FALSE}
## Load datasets  
#HSI: Weekly ID-based data
phyraw <- read.csv('./data/ground_truth/phyraw_forHSI_2022.csv', header = T, sep = ',', dec = '.')
ref_meta <- read.csv('./data/hyperspectral_imaging/HSI_side_for_biotraits_mod_W9.csv', header = T, sep = ',', dec = '.')
inVar <- "C"
file_path <- "./results/relieF_plsr/carbon/"

```

```{r, echo = F, fig.align='center', fig.width = 4, fig.height = 4}
trait <- phyraw %>%
  select("ID", all_of(inVar), "Treatment") %>%
  na.omit() 
#table(trait$Treatment) #N1:44, N2:44
```

## Step 1: Feature selection    

```{r, echo=FALSE, fig.align='center', fig.width = 10, fig.height = 4}
ref <- ref_meta[which(ref_meta$ID %in% trait$ID), -c(746:766)] #drop columns with wv > 2500 and meta data 
ref_trait <- merge(ref, subset(trait, select = -Treatment), by = "ID")
ref_trait_num <- ref_trait[ ,-1] #remove ID

ref_trait_expRank <- attrEval(C ~., ref_trait_num, estimator = "RReliefFexpRank", ReliefIterations = nrow(trait)*50) 
ref_trait_expRank_long <- data.frame(value = unname(ref_trait_expRank), 
                                       wv = as.numeric(gsub("_", ".", sub("...", "",  names(ref_trait_expRank)))))
critical_value <- ref_trait_expRank_long[order(ref_trait_expRank_long$value, decreasing = T)[300], 1]
ref_trait_expRank_long$select <- ifelse(ref_trait_expRank_long$value >= critical_value, "Y", "N")

ref_trait_expRank_order <- ref_trait_expRank_long[order(ref_trait_expRank_long$value, decreasing = T)[1:300], ] 
ref_trait_expRank_export <- ref_trait_expRank_long[order(ref_trait_expRank_long$value, decreasing = T), ]
#write.csv(file = paste0(file_path, "ref_trait_expRank.csv"), x= ref_trait_expRank_export, row.names = F)
col_attr <- c("Y"="red", "N"="darkgray")
C_feature_plot <- ggplot() +
  geom_line(aes(x = wv, y = value), data = ref_trait_expRank_long, col = "black", size = 0.5) +
  scale_x_continuous(breaks = seq(400, 2500, by = 400), labels = seq(400, 2500, by = 400)) +
  geom_point(aes(x = wv, y = value, col = select), data = ref_trait_expRank_long, size = .7,
             show.legend = F) +
  scale_color_manual(values=col_attr) +
  labs(x= "Wavelength (nm)", y = "Attributes values") +                     
  theme_bw() +
  theme(
    axis.title = element_text(size = 25, face = "bold"),
    axis.text = element_text(size = 25, face = "bold"),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
        )
C_feature_plot
```
Figure 1: Attributes values of HSI data on Week 9 for carbon (%). Wavelengths with the top 300 attribute values are considered as important (red, $W_{PLSR}$) and are used for model input.

## Step 2: plsr  

Method for pls: Orthogonal scores PLSR  

```{r plsr setting, include=FALSE}
`%notin%` <- Negate(`%in%`)
pls::pls.options(plsralg = "oscorespls")
pls::pls.options("plsralg")
opar <- par(no.readonly = T)
```
1. Prepared calibration and validation datasets  
The data were first grouped by treatment. Then, 80% of the data were sampled for the calibration dataset.

```{r, echo = F, fig.align='center', fig.width = 9, fig.height = 5}
ref_select <- as.matrix(ref[ ,names(ref_trait_expRank[ref_trait_expRank >= critical_value])])
plsr_data <- data.frame(trait, Spectra = I(ref_select))
set.seed(444)
prop <- 0.8
group_variables <- c("Treatment")
cal.plsr.data <- plsr_data %>% 
        group_by_at(vars(all_of(group_variables))) %>%
        slice(sample(1:n(), prop*n())) %>% 
        data.frame()
val.plsr.data <- plsr_data[!plsr_data$ID %in% cal.plsr.data$ID,]
print(paste("Cal observations: ",dim(cal.plsr.data)[1],sep="")) #70
print(paste("Val observations: ",dim(val.plsr.data)[1],sep="")) #18

cal_hist_plot <- qplot(cal.plsr.data$C, geom="histogram", bins =8,
                       main = "Cal. (n =70)",
                       xlab = "Carbon (%)", ylab = "Count", 
                       fill=I("#0072B2"), col=I("black")) + theme_bw(base_size = 18)
val_hist_plot <- qplot(val.plsr.data$C, geom="histogram", bins =5,
                       main = "Val. (n = 18) ",
                       xlab = "Carbon (%)", ylab = "Count", 
                       fill=I("#0072B2"),col=I("black")) + theme_bw(base_size = 18)
#val_hist_plot
cal_val_histograms <- grid.arrange(cal_hist_plot, val_hist_plot, ncol=2)
#ggsave(filename = paste0(file_path, "cal_val_Carbon_histograms.png"), plot = cal_val_histograms, device="png", width = 30, height = 12, units = "cm", dpi = 300)
#write.csv(cal.plsr.data, file = paste0(file_path, "Carbon_Cal_PLSR_Dataset.csv"), row.names=FALSE)
#write.csv(val.plsr.data, file = paste0(file_path, "Carbon_Val_PLSR_Dataset.csv"), row.names=FALSE)

```
Figure 2: Frequency distributions of carbon (%) in the calibration (left, *n* = 70) and validation (right, *n* = 18) datasets. 
\newpage  

2. Fitted a plsr model  

```{r determine number of components, echo = F, fig.align='center', fig.width = 7, fig.height = 5}
plsr.ini <- plsr(C~Spectra, scale=FALSE,
                 validation="LOO",trace=FALSE,data=cal.plsr.data)

min_selectNcomp <- function(object,
                        method = c("randomization", "onesigma"),
                        nperm = 999, alpha = 0.01, ncomp = object$ncomp,
                        plot = FALSE, ...) {
    if (!isTRUE(object$validation$method == "CV"))
        stop("No cross-validation data available in model")
    ## check that Y is univariate
    if (dim(residuals(object))[2] > 1)
        stop("Only univariate response supported")

    rmseps <- c(RMSEP(object, "CV")$val) ## includes zero
    maxIdx <- ncomp + 1
    absBest <- which.min(rmseps[seq_len(maxIdx)])

    if (absBest > 0) {
        method <- match.arg(method)
        if (is.null(origResponse <- object$y))
            origResponse <-
                c(predict(object, ncomp = 1) + residuals(object)[,1,1])

        ## include LOO prediction with zero components (i.e., the
        ## mean). For the mean we should also use the LOO estimate...
        allresids <- cbind(origResponse -
                               (sum(origResponse) - origResponse) /
                                   (length(origResponse) - 1),
                           object$validation$pred[,1,] - origResponse)

        if (method == "randomization") {
            pvals <- sapply(seq_len(absBest - 1),
                            function(ii) randomiz.test(allresids[,ii],
                                                       allresids[,absBest],
                                                       nperm = nperm))
            idx <- which(pvals > alpha)
            selection <- min(c(idx, absBest)) - 1
        } else {
            residsds <- apply(allresids, 2, sd) / sqrt(nrow(allresids)) #se of the residuals
            uls <- rmseps - residsds
            selection <- absBest - 1
        }

        if (isTRUE(plot)) {
            xvals <- seq_along(rmseps) - 1
            plot(xvals, rmseps, ylab = "RMSEP",
                 xlab = "Number of components", type = "b", ...)
            if (method == "onesigma") {
                arrows(xvals, uls, xvals, rmseps + residsds,
                       code = 3, col = "gray", angle = 90, length = .1)
            } else {
                points(xvals[idx], rmseps[idx], cex = 2, col = 4)
            }
            abline(h = rmseps[absBest], col = "gray", lty = 3)
            abline(v = absBest - 1, col = "blue", lty = 3)
        }

        selection
    } else {
        warning("Lowest CV error found at 0 components, no testing performed")
        0
    }
}


#png(filename = paste0(file_path, "Nitrogen_nComps.png"), bg = "white", width = 7, height = 5, units = "in", res = 400)
par(mfrow=c(1,1), mar=c(6,7,1,0.5), oma=c(0, 0.1, 0, 0.2), mgp = c(3, 1, 0))
nComps <- min_selectNcomp(plsr.ini, method = "onesigma", plot = T, lwd=1.6,
                      xlim = c(0, 15), 
                      pch=21, col="black", bg = "grey70",
                      cex.axis = 2, cex.lab = 2, font.lab = 2, font = 2) 
box(lwd=2.2)
#dev.off()
```
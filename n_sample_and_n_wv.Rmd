---
title: "Hyperparameters: n sample and n wavelengths"
date: "`r Sys.Date ()`"
output:
  pdf_document: default
---

```{r, setup, include=FALSE, cache = F}
knitr::opts_chunk$set(echo = T)
knitr::opts_knit$set(root.dir = '/Users/ting15/Dropbox/Ting_Wang/rice_imaging_ms')
#knitr::opts_knit$set(root.dir = 'C:/Users/rebec/Dropbox/Ting_Wang/rice_imaging_ms')
```

```{r, echo = F, include=FALSE}
rm(list = ls())
## Load package 
list.of.packages <- c("tidyverse", "dplyr", "reshape2", "ggplot2", "pls", "scales", "kableExtra", "ggpubr", "gridExtra", "CORElearn", "spectratrait")
invisible(lapply(list.of.packages, library, character.only = TRUE))
```

```{r import data, include=FALSE}
phyraw <- read.csv('./data/ground_truth/phyraw_forHSI_2022.csv', header = T, sep = ',', dec = '.')
ref_meta <- read.csv('./data/hyperspectral_imaging/HSI_side_for_biotraits_mod_W9.csv', header = T, sep = ',', dec = '.')
ref_meta = ref_meta[ ,-c(746:762)] # remove wv > 2500
file_path <- "./results/n_sample_n_wavelength"
```

```{r select a trait from all the traits, echo = F}
y_metadata <- phyraw %>%
  select("ID", "N", "Treatment", "Subpop") %>%
  mutate(ID = as.factor(ID)) %>%
  na.omit()

X_IDdata <- ref_meta %>%
  select(!c(Accession, Subpop, Country, Treatment)) %>%
  mutate(ID = as.factor(ID)) %>%
  filter(ID %in% y_metadata$ID)
#max(X_IDdata[,-1]) The highest reflectance was 0.6682433
cal.ID <- y_metadata %>% 
  select(ID, Treatment) %>%
  group_by_at(vars(all_of("Treatment"))) %>%
  slice(sample(1:n(), 0.8*n())) %>% #change to other ratio if needed
  ungroup()%>%
  select(-Treatment)%>%
  as.matrix() %>%
  as.vector()

val.ID = as.character(y_metadata[!y_metadata$ID %in% cal.ID, "ID"])

print(cal.ID)
print(val.ID)

num_X_names = as.numeric(gsub("_", ".", sub("...", "",  names(X_IDdata[,-1]))))
names(X_IDdata) = c("ID", as.character(num_X_names))
y_name = "N"
``` 

## Step 1: Feature selection    

```{r feature selection, echo=FALSE}
input_for_reliefF = function(X_IDdata, y_metadata, cal.ID, y_name, num_X_names){
  y_cal = y_metadata[y_metadata$ID %in% cal.ID, ]
  X_cal = X_IDdata[X_IDdata$ID %in% cal.ID, ]
  
  data_ID <- merge(X_cal, subset(y_cal, select = -c(Treatment, Subpop)), 
                     by = "ID")
  data <- data_ID[ ,-1] # drop ID
  names(data) = c(num_X_names, y_name)
  
  return(data)
}

feature_selection = function(pre_cal, y_name, num_X_names, n_feature){
  
    attr <- attrEval(y_name, pre_cal, estimator = "RReliefFexpRank",
                   ReliefIterations = nrow(pre_cal)*100)

    attr_long <- data.frame(value = unname(attr),
                            wv = num_X_names)
    attr_long_sort = attr_long[order(attr_long$value, decreasing = T)[1:n_feature],]
  
    return(attr_long_sort)
}


```
## Step 2: plsr  

```{r plsr setting, include=FALSE}
`%notin%` <- Negate(`%in%`)
pls::pls.options(plsralg = "oscorespls")
pls::pls.options("plsralg")
opar <- par(no.readonly = T)
```

```{r cal and vel prep in N, echo = F, fig.align='center', fig.width = 9, fig.height = 5}
cal_val_data_sets = function(cal.ID, val.ID, 
                             X_IDdata, y_metadata, X_attr, 
                             y_name, num_X_names,
                             plot=F, y_unit=NULL){
  
  X_select <- as.matrix(X_IDdata[ ,as.character(X_attr$wv)])
  
  cal.plsr.data = data.frame(y_metadata, 
                           Spectra=I(X_select))[y_metadata$ID %in% cal.ID, ]
  #print("Cal ID: ")
  #print(as.vector(cal.plsr.data$ID))
  
  val.plsr.data = data.frame(y_metadata, 
                           Spectra=I(X_select))[y_metadata$ID %in% val.ID, ]
  #print("Val ID: ")
  #print(as.vector(val.plsr.data$ID))
  
  if (isTRUE(plot)) {
        par(mfrow=c(1,2))
    hist(cal.plsr.data[ ,y_name], main="cal", xlab=paste0(y_name, y_unit))
    hist(val.plsr.data[ ,y_name], main="val", xlab=paste0(y_name, y_unit), 
         breaks = 3)}
  
 return(list(cal.plsr.data, val.plsr.data))
}
```

```{r plot cal and val spectra in N, echo=FALSE}
sel_wv_plotdata = function(data){
  data.df = as.data.frame(cbind(data$Spectra))
  names(data.df) = as.numeric(attr(data$Spectra, "dimnames")[[2]])
  data.df$ID = data$ID
  data.long = melt(data.df, id = "ID") %>% 
  mutate(variable = as.numeric(as.character(variable)), .keep="unused")
  return(data.long)
}

quantile_sel_ref = function(data, lo_q, hi_q){
  summary = data %>%
  group_by(variable) %>%
  summarize(mean_value=mean(value),
            lo=quantile(value, lo_q),
            hi=quantile(value, hi_q))
  names(summary)=c("wv", "mean_ref", "lo_ref", "hi_ref")
  summary_long = melt(summary, id="wv")
  return(summary_long)
}
```

```{r determine number of components in N, echo = F, fig.align='center', fig.width = 4, fig.height = 5}
if(grepl("Windows", sessionInfo()$running)){
  pls.options(parallel = NULL)
} else {
  pls.options(parallel = parallel::detectCores()-1)
}
maxComps <- 15
min_selectNcomp <- function(object, ncomp = maxComps, plot = FALSE, ...) {
    if (!isTRUE(object$validation$method == "CV"))
        stop("No cross-validation data available in model")
    ## check that Y is univariate
    if (dim(residuals(object))[2] > 1)
        stop("Only univariate response supported")
    ## includes zero component, the first element is the zero component
    rmseps <- c(RMSEP(object, "CV")$val) 
    maxIdx <- ncomp + 1
    absBest <- which.min(rmseps[seq_len(maxIdx)])
    selection <- absBest -1
    if (is.null(origResponse <- object$y))
      
        origResponse <- c(predict(object, ncomp = 1) + residuals(object)[,1,1])
    
    allresids <- cbind(origResponse-
                         (sum(origResponse)-origResponse)/(length(origResponse) - 1),
                       object$validation$pred[,1,] - origResponse)
        ## include LOO prediction with zero components (i.e., the
        ## mean). For the mean we should also use the LOO estimate...
    residsds <- apply(allresids, 2, sd) / sqrt(nrow(allresids))
    uls <- rmseps - residsds
    lls <- rmseps + residsds
    if (absBest > 0) {
      if (isTRUE(plot)) {
        par(mfrow=c(1,1), mar=c(6, 7, 1, 0.4), oma=c(0, 0.1, 0, 0.2), mgp = c(5, 2, 0))
# the first index should be zero component, but the rmseps considered it as the first element
            xvals <- seq_along(rmseps) - 1  
            plot(xvals, rmseps, ylab = "RMSEP",
                 xlab = "Number of components", type = "b", ...)
            arrows(xvals, uls, xvals, lls,
                   code = 3, col = "gray", angle = 90, length = .1)
            abline(h = rmseps[absBest], col = "gray", lty = 3)
            abline(v = absBest - 1, col = "blue", lty = 3)
        }
      selection
    } else {
        warning("Lowest CV error found at 0 components")
    }
}
```
  
```{r model metrics for N, echo = F}
model_metrics = function(model, nComps, cal.plsr.data, val.plsr.data, y_name){
  y_cal = cal.plsr.data[ ,y_name]
  y_cal_fit = model$fitted.values[,,nComps]
  PLSR_CV_Predicted = as.vector(model$validation$pred[,,nComps])
  PLSR_CV_Residuals = PLSR_CV_Predicted-y_cal
  #intercept = F, estimates for a model with zero component does not need to be returned
  cal.R2 <- round(pls::R2(model,intercept=F)[[1]][nComps],3) 
  cal.RMSEP <- round(sqrt(mean(PLSR_CV_Residuals^2)),3)
  cal_y_range <- range(y_cal)[2]-range(y_cal)[1]
  cal.NRMSEP <- round((sqrt(mean(PLSR_CV_Residuals^2))/cal_y_range)*100, 3) 
  
  y_val = val.plsr.data[ ,y_name]
  y_val_fit = as.vector(
    predict(model,newdata = val.plsr.data,ncomp=nComps,type="response")[,,])
  y_val_resids =  y_val_fit-y_val
  val.R2 <- round(pls::R2(model,newdata=val.plsr.data,intercept=F)[[1]][nComps],3)
  val.RMSEP <- round(sqrt(mean(y_val_resids^2)),3)
  val_y_range <- range(y_val)[2]-range(y_val)[1]
  val.NRMSEP <- round((sqrt(mean(y_val_resids^2))/val_y_range)*100,3)
  
  mm=data.frame(
    data_set=c("cal", "val"),
    R2 = c(cal.R2, val.R2),
    RMSEP = c(cal.RMSEP, val.RMSEP),
    NRMSEP = c(cal.NRMSEP, val.NRMSEP)
  )
  mm = mm%>%
    mutate(n_sample=rep(if_else(mm$data_set == "cal", 
                            dim(cal.plsr.data)[1], 
                            dim(val.plsr.data)[1]), nrow(mm)/2),
           tot_sample = rep(dim(cal.plsr.data)[1]+dim(val.plsr.data)[1], nrow(mm)),
           n_feature=rep(dim(as.data.frame(cbind(cal.plsr.data$Spectra)))[2],nrow(mm)),
           n_Comps=rep(nComps, nrow(mm)))
  return(mm)
           
}
```
## Step 3: Iteration  

```{r iterate over n-features, echo=FALSE}
maxComps = 15
sample_props = c(0.56, 0.7, 0.8, 0.9, 1)
rep = 100
features = c(10, 50, 100, 150, 200, 300, 400, 500, 600, 700)

sample_output = replicate(n = length(sample_props),
                        expr = {data.frame(matrix(ncol = 8, nrow = 2*length(features)*rep))},
                        simplify = F)

rep_output = replicate(n = rep,
                        expr = {data.frame(matrix(ncol = 8, nrow = 2*length(features)))},
                        simplify = F)

feature_output = replicate(n = length(features),
                        expr = {data.frame(matrix(ncol = 8, nrow = 2))},
                        simplify = F)

for (k in 1:length(sample_props)){
  
 for(i in 1:rep){
  
     y_sample <- y_metadata %>% 
     group_by_at(vars(all_of("Treatment"))) %>%
     slice(sample(1:n(), sample_props[k]*n())) %>% 
     ungroup()

     cal.ID <- y_sample %>% 
     select(ID, Treatment) %>%
     group_by_at(vars(all_of("Treatment"))) %>%
     slice(sample(1:n(), 0.8*n())) %>% 
     ungroup()%>%
     select(-Treatment) %>% as.matrix() %>% as.vector() 

     val.ID = as.vector(as.matrix(y_sample[!y_sample$ID %in% cal.ID, "ID"]))
     #print("After shuffling the data, Cal IDs are")
     #print(str_sort(cal.ID, decreasing = F))
     
     #print("After shuffling the data, Val IDs are")
     #print(str_sort(val.ID, decreasing = F))
     
     for (j in 1:length(features)){
       pre_cal = input_for_reliefF(X_IDdata = X_IDdata, y_metadata = y_metadata, 
                            cal.ID = cal.ID, y_name = y_name, 
                            num_X_names = num_X_names)
       X_attr = feature_selection(pre_cal = pre_cal, 
                                y_name = y_name, num_X_names = num_X_names, 
                                n_feature=features[j])
       # assemble cal and val data sets
       cal_val_list = cal_val_data_sets(cal.ID = cal.ID, val.ID = val.ID, 
                             X_IDdata = X_IDdata, y_metadata = y_metadata, X_attr = X_attr, 
                             y_name = y_name, num_X_names = num_X_names,
                             plot=F, y_unit=NULL)
        cal.plsr.data = cal_val_list[[1]]
        val.plsr.data = cal_val_list[[2]]
       # plsr
       plsr.ini <- plsr(N~Spectra, scale=FALSE,
                           validation="LOO",trace=FALSE,data=cal.plsr.data)
          
       nComps = min_selectNcomp(plsr.ini,ncomp = maxComps, plot = F, xlim = c(0, maxComps))
          
       plsr.out <- plsr(N~Spectra, scale=FALSE, ncomp = nComps,
                           validation="LOO",trace=FALSE,data=cal.plsr.data, jackknife=F)
       # model metrics
       feature_output[[j]] = model_metrics(model=plsr.out, nComps=nComps,
                            cal.plsr.data=cal.plsr.data, val.plsr.data=val.plsr.data,
                            y_name=y_name)
       #print(sprintf("%dth feature ends", j))
       }
  
  rep_output[[i]] = dplyr::bind_rows(feature_output)
  print(sprintf("%dth rep ends", i))}
  
sample_output[[k]] = dplyr::bind_rows(rep_output)
print(sprintf("%dth sample ends", k))
}

model_performance = dplyr::bind_rows(sample_output)
summary(model_performance)

```

```{r write output, echo=FALSE, eval=FALSE}
write.csv(x=model_performance, file = paste0(file_path, "/Augusto_sideview_N_sample.csv"), 
          row.names = F)
```

```{r loss curve from iterate over n-features, echo=FALSE}
model_performance_summary = model_performance %>%
group_by(data_set, n_feature, n_sample, tot_sample) %>%
summarise(len = n(),
          m_R2 = mean(R2),
          se_R2 = sd(R2)/sqrt(length(R2)),
          m_RMSEP = mean(RMSEP),
          se_RMSEP = sd(RMSEP)/sqrt(length(RMSEP)),
          m_NRMSEP = mean(NRMSEP),
          se_NRMSEP = sd(NRMSEP)/sqrt(length(NRMSEP)),
          m_nComps = mean(n_Comps),
          se_nComps = sd(n_Comps)/sqrt(length(n_Comps))
          ) 
print(model_performance_summary)
```

```{r summary output, echo=FALSE, eval=FALSE}
write.csv(x=model_performance_summary, 
          file = paste0(file_path, "/Augusto_sideview_N_summary.csv"), 
          row.names = F)
```

```{r read summary data, echo =F}
model_performance_summary <- read.csv('./results/n_sample_n_wavelength/Augusto_sideview_N_summary.csv', header = T, sep = ',', dec = '.')

```

```{r model performance facet by n sample NRMSEP, echo=FALSE}
NRMSEP_facet_by_sample_size = ggplot(aes(x = n_feature, y=m_NRMSEP, col = data_set), 
                data = model_performance_summary) +
  geom_errorbar(aes(y = NULL, 
                    ymin=m_NRMSEP-se_NRMSEP, 
                    ymax=m_NRMSEP+se_NRMSEP), width=50, color = "black")+
  facet_wrap(vars(tot_sample), ncol = 5)+
  geom_point()+
  geom_line()+
  scale_color_manual(values = c("cal" = "turquoise1", "val" = "violetred1"))+
  theme_bw(base_size = 8)+
  labs(title = "", x="Number of wavelengths", y="NRMSEP (%)", col = "")+
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        legend.position = "top",
        axis.text.x = element_text(angle = 90))
NRMSEP_facet_by_sample_size
```
Fifty wavelengths are enough to make predictions.  
Using 62 samples for calibration generalizes the model better than using 70 samples.   

```{r model performance facet by n sample RMSEP, echo=FALSE}
RMSEP_facet_by_sample_size = ggplot(aes(x = n_feature, y=m_RMSEP, col = data_set), data = model_performance_summary) +
  facet_wrap(vars(tot_sample), ncol = 5)+
  geom_errorbar(aes(y = NULL, 
                    ymin=m_RMSEP-se_RMSEP, 
                    ymax=m_RMSEP+se_RMSEP), width=50, color = "black")+
  geom_point()+
  geom_line()+
  scale_color_manual(values = c("cal" = "turquoise1", "val" = "violetred1"))+
  theme_bw(base_size = 8)+
  labs(title = "", x="\n Number of wavelengths", y="RMSEP (N %)", col = "")+
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        legend.position = "top",
        axis.text.x = element_text(angle = 90))
RMSEP_facet_by_sample_size
```
RMSEP supports the idea that calibration samples of 70 generalizes model better than calibration samples of 62.  
Validation performs better than calibration in might just be by chance.  
At least 62 calibration samples are needed and 50 wavelengths are sufficient.  

```{r model performance facet by n sample R2, echo=FALSE}
R2_facet_by_sample_size = ggplot(aes(x = n_feature, y=m_R2, col = data_set), data = model_performance_summary) +
  geom_errorbar(aes(y = NULL, 
                    ymin=m_R2-se_R2, 
                    ymax=m_R2+se_R2), width=50, color = "black")+
  facet_wrap(vars(tot_sample), ncol = 5)+
  geom_point()+
  geom_line()+
  scale_color_manual(values = c("cal" = "turquoise1", "val" = "violetred1"))+
  theme_bw(base_size = 8)+
  labs(title = "", x="Number of wavelengths", y=expression(R^2), col = "")+
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        legend.position = "top",
        axis.text.x = element_text(angle = 90))
R2_facet_by_sample_size
```
Results from R2 were similar with RMSEP.  

We saw that R2 and RMSEP had different results than NRMSEP. NRMSEP was the normalized results. Because our samples are limited. Different degree of variations in calibration and validation datasets might have a strong influence on model metrices. In this case, using normalize model metrices, such as NRMSEP, might provide more accurate information.  
```{r save plots facetted by sample size, echo=FALSE, eval=FALSE}
ggsave(filename = paste0(file_path, "/NRMSEP.pdf"), 
       plot = NRMSEP_facet_by_sample_size, 
       device = "pdf", width = 8, height = 6, units = "cm", dpi = 400)
ggsave(filename = paste0(file_path, "/RMSEP.pdf"), 
       plot = RMSEP_facet_by_sample_size, 
       device = "pdf", width = 8, height = 6, units = "cm", dpi = 400)
ggsave(filename = paste0(file_path, "/R2.pdf"), 
       plot = R2_facet_by_sample_size, 
       device = "pdf", width = 8, height = 6, units = "cm", dpi = 400)
```

```{r test code, echo=FALSE}
pre_cal = input_for_reliefF(X_IDdata = X_IDdata, y_metadata = y_metadata, 
                            cal.ID = cal.ID, y_name = y_name, 
                            num_X_names = num_X_names)
N_attr_long = feature_selection(pre_cal = pre_cal, 
                                y_name = y_name, num_X_names = num_X_names, 
                                n_feature=100)
head(N_attr_long)

N_cal_val_list = cal_val_data_sets(cal.ID = cal.ID, val.ID = val.ID,
                                   X_IDdata = X_IDdata, y_metadata = y_metadata, 
                                   X_attr = N_attr_long, 
                                   y_name = y_name, num_X_names = num_X_names,
                                   plot = T, y_unit = " (%)")

N.cal.plsr.data = N_cal_val_list[[1]]

N.val.plsr.data = N_cal_val_list[[2]]

N_cal.plsr.long = sel_wv_plotdata(N.cal.plsr.data)
#str(N_cal.plsr.long)
N_val.plsr.long = sel_wv_plotdata(N.val.plsr.data)
#str(val.plsr.long)
N_sel_wv_ref_min = range(N_cal.plsr.long$value, N_val.plsr.long$value)[1]
N_sel_wv_ref_max = range(N_cal.plsr.long$value, N_val.plsr.long$value)[2]

summary_ref_col = c("mean_ref" = "forestgreen", "lo_ref"="green", "hi_ref"="green")
N_summary_cal_long = quantile_sel_ref(data = N_cal.plsr.long, 0.25, 0.75)
#str(summary_cal_long)
N_summary_val_long = quantile_sel_ref(data = N_val.plsr.long, 0.25, 0.75)
#str(summary_val_long)

N_cal_ref_95perc = ggplot()+
  geom_point(aes(x=variable, y=value, group=ID), data=N_cal.plsr.long,
             size=0.3, color="grey")+
  geom_point(aes(x=wv, y=value, col=variable), data = N_summary_cal_long, 
             size=0.5, show.legend = F)+
  scale_color_manual(values = summary_ref_col)+
  scale_y_continuous(breaks = seq(N_sel_wv_ref_min, N_sel_wv_ref_max, length.out = 3), 
                     labels = round(seq(N_sel_wv_ref_min, N_sel_wv_ref_max, length.out = 3), 3),
                     limits = c(N_sel_wv_ref_min, N_sel_wv_ref_max)) +
  labs(title = "N calibration data set", x= "Wavelength (nm)", y = "Reflectance") +
  theme_bw(base_size=18) +
  theme(
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
        )

N_val_ref_95perc = ggplot()+
  geom_point(aes(x=variable, y=value, group=ID), data=N_val.plsr.long,
             size=0.3, color="grey")+
  geom_point(aes(x=wv, y=value, col=variable), data = N_summary_val_long, 
             size=0.5, show.legend = F)+
  scale_color_manual(values = summary_ref_col)+
  scale_y_continuous(breaks = seq(N_sel_wv_ref_min, N_sel_wv_ref_max, length.out = 3), 
                     labels = round(seq(N_sel_wv_ref_min, N_sel_wv_ref_max, length.out = 3), 3),
                     limits = c(N_sel_wv_ref_min, N_sel_wv_ref_max)) +
  labs(title = "N validation data set", x= "Wavelength (nm)", y = "Reflectance") +
  theme_bw(base_size=18) +
  theme(
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
        ) 

N_ref_95perc = ggarrange(N_cal_ref_95perc, N_val_ref_95perc, nrow = 2)
N_ref_95perc

N_plsr.ini <- plsr(N~Spectra, scale=FALSE,
                 validation="LOO",trace=FALSE,data=N.cal.plsr.data)

N_nComps = min_selectNcomp(N_plsr.ini,plot = T,
                lwd=1.6,xlim = c(0, maxComps),pch=21, col="black", 
                bg = "grey70", cex.axis = 2, cex.lab = 2, font.lab = 2, font = 2)
N_plsr.out <- plsr(N~Spectra, scale=FALSE, ncomp = N_nComps,
                 validation="LOO",trace=FALSE,data=N.cal.plsr.data, jackknife=F)
N_mm=model_metrics(model=N_plsr.out, nComps=N_nComps,
                    cal.plsr.data=N.cal.plsr.data, val.plsr.data=N.val.plsr.data,
                    y_name=y_name)
print(N_mm)
```
